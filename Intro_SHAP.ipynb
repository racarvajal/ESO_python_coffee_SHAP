{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESO Python Coffee - May 29, 2024\n",
    "# (Short) Introdution to SHAP\n",
    "\n",
    "### R. Carvajal (IA - FCUL, Portugal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapley values (Shapley, 1953) are a method from coalitional game theory that tells us how to fairly distribute the dividends (the prediction in our case) among the features of a function (see a thorough description in its Wikipedia [article](https://en.wikipedia.org/wiki/Shapley_value))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHapley Additive exPlanations (SHAP, [documentation](https://shap.readthedocs.io/en/latest/) and [repository](https://github.com/shap/shap)) is a Python package that can obtain Shapley values (or a very good approximation) from general functions, including complex Machine Learning (ML) models.\n",
    "\n",
    "These ML models are often treated as \"black boxes\" because their internal workings are difficult to understand. SHAP helps understanding them by revealing how each piece of data (a feature) influences the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to other methods and packages, SHAP can extract information from individual predictions. This means we can go beyond understanding the overall importance of features and know how each prediction `moves' inside the function or model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP values (the output from SHAP) tell us how much each feature in a model (or other function) impacts its final predictions. They do this by comparing the actual model output to what the it would predict if that specific feature had a different value. Essentially, they calculate the difference between the prediction with a specific feature and the model's expected prediction without it.\n",
    "\n",
    "In simpler terms, SHAP values show how much each feature \"pushes\" the model's prediction in a certain direction (positive or negative) compared to a baseline.  The higher the absolute SHAP value (positive or negative), the bigger the impact that feature has on the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show two short examples of how to use and interpret SHAP values from simple functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we install and import all the packages we will need,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install astropy\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from PIL import Image\n",
    "from joblib import dump, load\n",
    "import shap\n",
    "import helper_functions as helpers  # own file with functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function and data set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first example, we will use a polynomial and we will try to determine their strongest factors.\n",
    "\n",
    "We will create a polynomial of degree 5 of the form:\n",
    "\n",
    "$$ f(x) = 1.5 + x_{1} + 2 x_{2}^{2} - 3 x_{3}^{3} + 0.8 x_{4}^{4} - 0.5 x_{5}^{5}$$\n",
    "\n",
    "with\n",
    "\n",
    "$$x = (x_{0}, x_{1}, x_{2}, x_{3}, x_{4}, x_{5})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = [1.5, 1, 2, -3, 0.8, -0.5]\n",
    "degree = 5\n",
    "nelems = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define that polynomial in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_pol(x):\n",
    "  # x is a 5D vector\n",
    "  # 1.5 + x1 + 2 x2^2 -3 x3^3 + 0.8 x4^4 - 0.5 x5^5\n",
    "  pol = 0\n",
    "  for count in np.arange(degree + 1):\n",
    "    pol += coeffs[count] * x[:, count]**(count)\n",
    "  return pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the set of input values for our function, x.\n",
    "\n",
    "In this case, random values bewtween $-2$ and $2$.\n",
    "\n",
    "Also, and for clarity, we name each column (feature) of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng          = np.random.default_rng()\n",
    "data_rand    = rng.uniform(low=-2, high=2, size=(nelems, degree + 1))\n",
    "data_rand_df = pd.DataFrame(data_rand, columns=['Degree_0', 'Degree_1', 'Degree_2',\n",
    "                                                'Degree_3', 'Degree_4', 'Degree_5'])\n",
    "display(data_rand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check their output values from our polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_pol(data_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the impact of each element of the polynomial, we can plot how it behaves when all the elements of the vectors are zero ($0$) except that of the analysed degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_polynomial_degrees(func_pol, coeffs=coeffs, degree=degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, for instance, that the first-degree term remains constant regardless of the value of $x_{0}$.\n",
    "\n",
    "Then, the remaining terms behave as we would expect times their coefficient. In this way, the term with the largest range of values is the third-degree factor (i.e. $[-25,25]$, even more than the fift-degree term).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start our SHAP analysis. First, we need to create an `Explainer` object with our function and the data it uses for training (in a ML context). Some relevant attributes are:\n",
    "\n",
    "- `expected_value`\n",
    "- `shap_values()`\n",
    "\n",
    "\n",
    "Then, we can apply that explainer to the data we want to explain. It will output an `Explanation` object with the following relevant attributes:\n",
    "\n",
    "- `feature_names`\n",
    "- `data`\n",
    "- `base_values`\n",
    "- `values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`expected_value` will output the mean value of all predictions for our dataset. This value is used by SHAP to obtain their impact on the final predictions. Recall that SHAP values are relative to their base value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_names` outputs the name of the features used in our traininig (or background) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`base_values` will, by default, replicate the `expected_value` from the `Explainer` for each feature. But, these `base_values` can be modified as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of `Explainer` objects. A full list is shown [here](https://shap.readthedocs.io/en/latest/api.html).\n",
    "\n",
    "We have selected the `KernelExplainer`, which implements a linear regression for the computation of feature importances of any model and function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_func    = shap.KernelExplainer(func_pol, data_rand_df)\n",
    "explanations_func = explainer_func(data_rand_df)\n",
    "shap_values_func  = explanations_func.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_func.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_func.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_func.base_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From their theoretical definition, SHAP values are linear and can be combined and compared between them. For that reason, we are able to re-scale them to express the percentage of impact over the total prediction. We do this and also show the cumulative impact of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_func_df = helpers.tabular_shap_vals(explanations_func)\n",
    "display(explanations_func_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis of the previous table, we can see that the most impactful factor is the third-degree coefficient (much more than the fift-degree element). Also, if we created a new polynomial, but without the first and zeroth-degree coefficient, the final results would be almost the same of the original function ($\\sim 95 \\%$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP package implements several graphical tools for the analysis of their values.\n",
    "We will start with the simplest plot.\n",
    "\n",
    "The bar plot shows the mean absolute value of the SHAP values among the target dataset. These values are sorted by importance as to highlight their relative importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values=explanations_func,\n",
    "                max_display=len(explanations_func.feature_names),\n",
    "                show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second visualization is the Decision Plot. It shows how each data instance arrives to its final prediction or output after being fed to our target function or model.\n",
    "\n",
    "The x-axis represents the model’s output. For a classification ML model, the units would be log odds. The plot is centered on the x-axis at `expected_value`. The y-axis lists the model’s features. By default, the features are ordered by descending importance. The importance is calculated over the observations plotted. Each observation’s prediction is represented by a colored line. At the top of the plot, each line strikes the x-axis at its corresponding observation’s predicted value. This value determines the color of the line on a spectrum. * Moving from the bottom of the plot to the top, SHAP values for each feature are added to the model’s base value. This shows how each feature contributes to the overall prediction. * At the bottom of the plot, the observations converge at explainer.expected_value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a decision plot for all the values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(explainer_func.expected_value,\n",
    "                    shap_values_func,\n",
    "                    data_rand_df,\n",
    "                    plot_color='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how relevant the third-degree term is for the final output. Also, we can notice the null impact of the zeroth-order factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to create Decision Plots for each individual element of the dataset. We will do it for the three first element of our sample.\n",
    "\n",
    "In each row, the plot shows the value of the selected element that goes into each coefficient. That is, the value of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in np.arange(nelems)[:3]:\n",
    "    shap.decision_plot(explainer_func.expected_value,\n",
    "                        shap_values_func[count],\n",
    "                        data_rand_df.loc[count],\n",
    "                        plot_color='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP package can be used with regular functions, as in this example. It can also be applied to all sorts of ML models (random forests, image models, NNs, and more).\n",
    "\n",
    "Additional plots are available to assess the impact of each feature in the final output of the studied functions and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Astronomical example: Redshift prediction in SDSS QSOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will obtain SHAP values for a simple ML model that predicts redshift values for QSOs from the SDSS-DR16Q (Lyke et al. 2020) dataset with photometric measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load our data and select the relevant features: redshift, SDSS magnitudes, GALEX magnitudes, *WISE* magnitudes, 2MASS magnitudes, and *Gaia* proper motions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDSS_data_table = Table.read('./data/DR16Q_v4_measured_test.fits')\n",
    "SDSS_data_table.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2_use_SDSS = ['Z', 'PSFMAG_u', 'PSFMAG_g', 'PSFMAG_r',\n",
    "                    'PSFMAG_i', 'PSFMAG_z', 'FUV_MAG', 'NUV_MAG',\n",
    "                    'W1_MAG', 'W2_MAG', 'JMAG', 'HMAG', 'KMAG',\n",
    "                    'GAIA_PM_RA', 'GAIA_PM_DEC']\n",
    "                    \n",
    "SDSS_data_df = SDSS_data_table.to_pandas().loc[:, cols_2_use_SDSS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the logarithmic nature of redshifts, we create a function for the comparison of true and predicted redshifts through their bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_z(y_true, y_pred, **kwargs):\n",
    "    num = np.abs(y_true - y_pred)\n",
    "    den = 1 + y_true\n",
    "    return np.nanmedian(num / den)\n",
    "\n",
    "bias_z_scorer = make_scorer(score_func=bias_z, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reserve a $20\\%$ of the dataset for testing the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(SDSS_data_df.drop(columns=['Z'], inplace=False),\n",
    "                                                    SDSS_data_df.loc[:, 'Z'],\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42)\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation, fitting, and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Random Forest regressor for the prediction of redshifts. We create the object and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_SDSS = RandomForestRegressor(max_depth=4, random_state=42, verbose=1)\n",
    "regr_SDSS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to know how well our predictions are in the test subset. We calculate, with cross-validation, the bias of the sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_SDSS = -cross_val_score(regr_SDSS,\n",
    "                                    X_test,\n",
    "                                    y_test,\n",
    "                                    cv=10,\n",
    "                                    scoring=bias_z_scorer,\n",
    "                                    verbose=0)\n",
    "\n",
    "y_pred_test      = regr_SDSS.predict(X_test)\n",
    "\n",
    "print('-'*30)\n",
    "print(f'Testing bias is {np.nanmean(test_scores_SDSS):.3f} ± {np.nanstd(test_scores_SDSS):.3f}')\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the predicted and true values to see the performance of the model on the test set.\n",
    "The model could do better, but this is not our goal in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_redshifts(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create all SHAP objects and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_SDSS   = shap.TreeExplainer(regr_SDSS)\n",
    "explanation_SDSS = explainer_SDSS(X_test)\n",
    "shap_values_SDSS = explanation_SDSS.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP values can be re-scaled to be shown as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_SDSS_df = helpers.tabular_shap_vals(explanation_SDSS)\n",
    "display(explanations_SDSS_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot for mean absolute SHAP values of test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values=explanation_SDSS,\n",
    "                max_display=len(explanation_SDSS.feature_names),\n",
    "                show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the most important feature, by far, is the *W1* magnitude (from *WiSE*), followed closely by the combination of GALEX magnitudes.\n",
    "\n",
    "Also, *Gaia* proper motions make almost no difference in the prediction of QSO redshifts. Was this expected?\n",
    "\n",
    "Discarding the last six features would not affect the final output by much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we display all test sources in a Decision plot. We can see that most of the impact starts to be noticeable from the u band (from bottom to top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(explainer_SDSS.expected_value,\n",
    "                    shap_values_SDSS,\n",
    "                    X_test,\n",
    "                    plot_color='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clarity, we plot the first ten sources of the test subset. We can see that the source with the highest predicted redshift has a behaviour different from the rest. Its r and u magnitudes are different, making it an outlier in this sample. Is it worth investigating it further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(explainer_SDSS.expected_value,\n",
    "                    shap_values_SDSS[:10],\n",
    "                    X_test.iloc[:10],\n",
    "                    plot_color='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another astronomical (toy) example: image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use SHAP for the analysis of images. In principle, SHAP can be used for classifiers that take images as input.\n",
    "\n",
    "In our case, we will use a function that 'predicts' if the mean value from the pixels in an image is larger than the median. In other words, we want to know, for no particular reason, if the distribution of pixel values is positively skewed or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Skewness_definition.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load a nice image of NGC3432. From Hubble, we can see very impressive star-forming regions throughout the galaxy.\n",
    "\n",
    "For our model, we turn the image into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./data/NGC3432.jpg')\n",
    "img_galaxy = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_galaxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(img_galaxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our model with NGC3432. We can see that its skewness is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.predict_galaxy(img_galaxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to create a SHAP explainer that takes an image and masks some regions to understand their impact in the final output. The larger the number of iterations, `n_evals`, the finer will be the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "n_evals = 1000 # 1000, 500, 300 evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a masker that is used to mask out partitions of the input image.\n",
    "masker_shap = shap.maskers.Image('inpaint_telea', img_galaxy.shape)\n",
    "\n",
    "# create an explainer with model and image masker\n",
    "explainer = shap.Explainer(helpers.predict_galaxy, masker_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block can take quite a while to run. I have run it previously and the results are saved in the repository. Thus, we can safely skip this step. But you can experiment with different number of iterations if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed only one image\n",
    "# here we explain two images using 1000 evaluations of the underlying model to estimate the SHAP values\n",
    "run_SHAP_block = False\n",
    "if run_SHAP_block:\n",
    "    shap_values_galaxy = explainer(\n",
    "        np.array([img_galaxy]),\n",
    "        max_evals=n_evals,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_SHAP_block:\n",
    "    try:\n",
    "        dump(shap_values, 'shap_values/shap_galaxy.joblib', compress=True)\n",
    "        print('SHAP values saved successfully!')\n",
    "    except Exception as e:\n",
    "        print('An error occurred while saving the values:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the saved SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_SHAP_block:\n",
    "    try:\n",
    "        shap_values_galaxy = load('shap_values/shap_galaxy.joblib')\n",
    "        print('SHAP values loaded successfully!')\n",
    "    except Exception as e:\n",
    "        print('An error occurred while loading the values:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, we check that our SHAP values have the same dimensions as the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(shap_values_galaxy.data.shape, shap_values_galaxy.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the SHAP values for NGC3432. We can see the impact that different regions of the image have in the final prediction. For instance, the central region of the galaxy makes it get negatively skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.image_plot(\n",
    "    shap_values=shap_values_galaxy.values,\n",
    "    pixel_values=shap_values_galaxy.data,\n",
    "    labels=shap_values_galaxy.output_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, SHAP values should be primarily applied in Machine Learning models, but we have see that it is possible to use them in very different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we can go beyond predictions with the use of feature importance methods. In particular, SHAP can help us obtaining very relevant information about the behaviour of the predicted elements inside models and functions. In Astrophysical contexts, we can use SHAP values to extract (hidden?) connections between features that can drive new discoveries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
